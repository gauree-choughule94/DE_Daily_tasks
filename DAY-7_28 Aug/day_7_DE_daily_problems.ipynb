{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"UserSessions\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"U1\", \"2025-01-01\"),\n",
        "    (\"U1\", \"2025-01-05\"),\n",
        "    (\"U1\", \"2025-01-10\"),\n",
        "    (\"U2\", \"2025-01-02\"),\n",
        "    (\"U2\", \"2025-01-04\")\n",
        "]\n",
        "\n",
        "columns = [\"user_id\", \"session_date\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# df.show()\n",
        "wind1 = Window.partitionBy(\"user_id\").orderBy('session_date')\n",
        "\n",
        "df1 = df.withColumn('lag1', lag('session_date').over(wind1))\n",
        "df1.show()\n",
        "\n",
        "df2 = df1.withColumn('days_since_last_session', date_diff(col('session_date'), col('lag1')))\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVElm0aj0_Ac",
        "outputId": "416c5845-6667-4dd8-b32e-ef584d39d989"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+\n",
            "|user_id|session_date|      lag1|\n",
            "+-------+------------+----------+\n",
            "|     U1|  2025-01-01|      NULL|\n",
            "|     U1|  2025-01-05|2025-01-01|\n",
            "|     U1|  2025-01-10|2025-01-05|\n",
            "|     U2|  2025-01-02|      NULL|\n",
            "|     U2|  2025-01-04|2025-01-02|\n",
            "+-------+------------+----------+\n",
            "\n",
            "+-------+------------+----------+-----------------------+\n",
            "|user_id|session_date|      lag1|days_since_last_session|\n",
            "+-------+------------+----------+-----------------------+\n",
            "|     U1|  2025-01-01|      NULL|                   NULL|\n",
            "|     U1|  2025-01-05|2025-01-01|                      4|\n",
            "|     U1|  2025-01-10|2025-01-05|                      5|\n",
            "|     U2|  2025-01-02|      NULL|                   NULL|\n",
            "|     U2|  2025-01-04|2025-01-02|                      2|\n",
            "+-------+------------+----------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "EIE3aGNCb0D0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc33dd0-b28f-4543-b557-75f8d7a35d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+\n",
            "|customer_id|amount_count|\n",
            "+-----------+------------+\n",
            "|         C1|           2|\n",
            "|         C3|           2|\n",
            "|         C2|           1|\n",
            "+-----------+------------+\n",
            "\n",
            "+-----------+\n",
            "|customer_id|\n",
            "+-----------+\n",
            "|         C2|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"EmployeeData\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"C1\", \"2025-01-01\", 200),\n",
        "    (\"C1\", \"2025-01-10\", 300),\n",
        "    (\"C2\", \"2025-01-05\", 150),\n",
        "    (\"C3\", \"2025-01-02\", 100),\n",
        "    (\"C3\", \"2025-01-04\", 200)\n",
        "]\n",
        "\n",
        "columns = [\"customer_id\", \"purchase_date\", \"amount\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "# df.show()\n",
        "\n",
        "df1 = df.groupBy('customer_id').agg(count('amount').alias('amount_count'))\n",
        "df1.show()\n",
        "df2 = df1.filter(col('amount_count')==1).select('customer_id')\n",
        "df2.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_sql = df.createOrReplaceTempView('customer_table')             # returns None\n",
        "\n",
        "df.createOrReplaceTempView('customer_table')\n",
        "\n",
        "result = spark.sql(\"\"\"\n",
        "select customer_id\n",
        "from customer_table\n",
        "group by customer_id\n",
        "having count('amount')==1\n",
        "\"\"\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcQpbsGsiqX1",
        "outputId": "cefa5e29-9598-4a74-b805-4e963dd87929"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|customer_id|\n",
            "+-----------+\n",
            "|         C2|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZ6waQrH6YzD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}