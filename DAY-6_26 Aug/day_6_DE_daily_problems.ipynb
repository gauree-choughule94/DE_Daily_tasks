{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EIE3aGNCb0D0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f31028-0adc-4374-c88d-4ca73d0666bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------+\n",
            "|emp_id|dept|salary|\n",
            "+------+----+------+\n",
            "|     1|  HR| 60000|\n",
            "|     2|  HR| 75000|\n",
            "|     3|  HR| 50000|\n",
            "|     4|  IT| 90000|\n",
            "|     5|  IT| 85000|\n",
            "+------+----+------+\n",
            "\n",
            "+------+----+------+-----+\n",
            "|emp_id|dept|salary|rank1|\n",
            "+------+----+------+-----+\n",
            "|     2|  HR| 75000|    1|\n",
            "|     1|  HR| 60000|    2|\n",
            "|     3|  HR| 50000|    3|\n",
            "|     4|  IT| 90000|    1|\n",
            "|     5|  IT| 85000|    2|\n",
            "+------+----+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"EmployeeData\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"HR\", 60000),\n",
        "    (2, \"HR\", 75000),\n",
        "    (3, \"HR\", 50000),\n",
        "    (4, \"IT\", 90000),\n",
        "    (5, \"IT\", 85000)\n",
        "]\n",
        "\n",
        "columns = [\"emp_id\", \"dept\", \"salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "df.show()\n",
        "\n",
        "win1 = Window.partitionBy('dept').orderBy(col('salary').desc())\n",
        "\n",
        "df1 = df.withColumn('rank1', rank().over(win1))\n",
        "df1.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ProductSales\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"P1\", \"2025-01-10\"), (\"P1\", \"2025-02-12\"), (\"P1\", \"2025-03-09\"),\n",
        "    (\"P1\", \"2025-04-18\"), (\"P1\", \"2025-05-03\"), (\"P1\", \"2025-06-27\"),\n",
        "    (\"P1\", \"2025-07-14\"), (\"P1\", \"2025-08-21\"), (\"P1\", \"2025-09-02\"),\n",
        "    (\"P1\", \"2025-10-11\"), (\"P1\", \"2025-11-06\"), (\"P1\", \"2025-12-05\"),\n",
        "\n",
        "    (\"P2\", \"2025-01-05\"), (\"P2\", \"2025-02-10\"), (\"P2\", \"2025-03-15\"),\n",
        "    (\"P2\", \"2025-05-20\"), (\"P2\", \"2025-06-08\"), (\"P2\", \"2025-07-22\"),\n",
        "    (\"P2\", \"2025-08-30\"), (\"P2\", \"2025-10-01\"), (\"P2\", \"2025-11-19\"),\n",
        "    (\"P2\", \"2025-12-07\"),\n",
        "\n",
        "    (\"P3\", \"2025-01-02\"), (\"P3\", \"2025-02-14\"), (\"P3\", \"2025-03-03\"),\n",
        "    (\"P3\", \"2025-04-25\"), (\"P3\", \"2025-05-09\"), (\"P3\", \"2025-06-16\"),\n",
        "    (\"P3\", \"2025-07-07\"), (\"P3\", \"2025-08-12\"), (\"P3\", \"2025-09-28\"),\n",
        "    (\"P3\", \"2025-10-20\"), (\"P3\", \"2025-11-03\"), (\"P3\", \"2025-12-29\"),\n",
        "]\n",
        "\n",
        "columns = [\"product_id\", \"sale_date\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "# df.show(40, truncate=False)\n",
        "df1 = df.select('product_id', date_format('sale_date', 'yyyy-MM').alias('month'))\n",
        "# df1.show()\n",
        "\n",
        "df2 = df1.groupBy('product_id').agg(countDistinct('month').alias(\"month_count\"))\n",
        "df2.show()\n",
        "\n",
        "res = df2.filter(col('month_count')==12).select('product_id').sort('product_id')\n",
        "res.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKrJg4I5hCbg",
        "outputId": "07cba664-b971-46e5-c3d5-0504f846ea20"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|product_id|month_count|\n",
            "+----------+-----------+\n",
            "|        P2|         10|\n",
            "|        P3|         12|\n",
            "|        P1|         12|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+\n",
            "|product_id|\n",
            "+----------+\n",
            "|        P1|\n",
            "|        P3|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lcQpbsGsiqX1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}